{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refining CaImAn components\n",
    "\n",
    "This notebook serves to refine spatiotemporal components extracted via CNMF from CaImAn (https://github.com/flatironinstitute/CaImAn; Giovannucci et al., 2019, eLife), using interactive quality threshold setting followed by manual curation.\n",
    "\n",
    "Author: Oliver Barnstedt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T07:58:53.339041Z",
     "start_time": "2020-05-26T07:58:53.302612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "user='OB'\n",
    "index=138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T07:59:03.899688Z",
     "start_time": "2020-05-26T07:58:55.045756Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'fun'))\n",
    "import ptm_base\n",
    "import ptm_caiman\n",
    "\n",
    "import tifffile\n",
    "from ipywidgets import interact, widgets, Layout\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import HoverTool, CustomJS, Button, LinearAxis, Range1d, Span, PointDrawTool, Slider, Legend\n",
    "from bokeh.models.glyphs import Circle, Ray\n",
    "from bokeh.layouts import row, column\n",
    "from bokeh.events import ButtonClick\n",
    "output_notebook()\n",
    "import caiman as cm\n",
    "from caiman.source_extraction.cnmf.cnmf import load_CNMF\n",
    "from caiman.utils import visualization as cmviz\n",
    "from scipy.stats import zscore\n",
    "import scipy\n",
    "from IPython.core.display import display, HTML, Markdown, clear_output\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "scaling = .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T07:59:46.466271Z",
     "start_time": "2020-05-26T07:59:45.986285Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IF NOT CONNECTED TO FILESERVER\n",
    "offline_folder = '/Users/Oliver/Google Drive/Imaging_Results/136_137_138/138/'\n",
    "cnm2_path = offline_folder+'OB_138_green_caiman_results2.hdf5'\n",
    "\n",
    "cnm3_path = cnm2_path[:-6]+'3.hdf5'\n",
    "cnm = load_CNMF(cnm2_path)\n",
    "Cn = tifffile.imread(offline_folder+'Cn.tiff')\n",
    "redAvg = tifffile.imread(offline_folder+'RedAvg.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T08:00:05.598888Z",
     "start_time": "2020-05-26T08:00:04.417534Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = ptm_base.readyaml(user, index, resultsdir='/Users/Oliver/Google Drive/Imaging_Results')\n",
    "if sys.platform=='darwin':\n",
    "    for key,value in params['paths'].items():\n",
    "        params['paths'][key] = value.replace('/mnt/', '/Volumes/')\n",
    "cnm_path = params['paths']['Results_Imaging_Green_caiman']\n",
    "cnm2_path = params['paths']['Results_Imaging_Green_caiman2']\n",
    "cnm3_path = cnm2_path[:-6]+'3.hdf5'\n",
    "current_cnm = params['paths']['Results_Imaging_Green_caiman2'] if os.path.exists(params['paths']['Results_Imaging_Green_caiman2']) else params['paths']['Results_Imaging_Green_caiman']\n",
    "\n",
    "if 'Results_Imaging_Green_caiman' not in params['paths']:\n",
    "    sys.exit(\"No analyzed imaging data found.\")\n",
    "else:\n",
    "    print(\"Loading CaImAn H5 results file \"+str(current_cnm)+\"...\")\n",
    "    cnm = load_CNMF(current_cnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T08:01:37.675680Z",
     "start_time": "2020-05-26T08:01:37.662470Z"
    }
   },
   "outputs": [],
   "source": [
    "# cnm_mmap_file = glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], '*memmap*order_C*mmap'))[0]\n",
    "# # cnm_mmap_file = cnm.mmap_file  # manually change mmap file path if file has been moved since creation of cnm file\n",
    "# # cnm_mmap_file = '/mnt/ag-remy-2/Imaging/OB/Results/103_104_105_106/103/20191008/OB_103_green_ds_memmap__d1_266_d2_266_d3_1_order_C_frames_9000_.mmap'#cnm.mmap_file  # manually change mmap file path if file has been moved since creation of cnm file\n",
    "# print(\"Loading 'C' memmap file from \"+str(cnm_mmap_file))\n",
    "# Yr, dims, T = cm.load_memmap(cnm_mmap_file)  # loading 'C' memmap file\n",
    "# images = np.reshape(Yr.T, [T] + list(dims), order='F')  # load frames in python format (T x X x Y)\n",
    "    \n",
    "# EVALUATE / DECONVOLVE COMPONENTS IF NOT YET DONE\n",
    "if not cnm.estimates.F_dff.any():\n",
    "    print(\"Detrending dF/F...\")\n",
    "    cnm.estimates.detrend_df_f()\n",
    "if not hasattr(cnm.estimates, 'S_dff'):\n",
    "    print(\"No detrended deconvolution calculated yet. Running it now...\")\n",
    "    cnm.estimates.deconvolve(cnm.params, dff_flag=True)\n",
    "if hasattr(cnm.estimates, 'cnn_preds'):\n",
    "    if not cnm.estimates.cnn_preds.any():\n",
    "        print(\"Components not yet evaluated. Running component evaluation now...\")\n",
    "        cnm.estimates.evaluate_components(images, cnm.params)\n",
    "else:\n",
    "    print(\"Components not yet evaluated. Running component evaluation now...\")\n",
    "    cnm.estimates.evaluate_components(images, cnm.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnm_path = params['paths']['Results_Imaging_Green_caiman2']\n",
    "# cnm.save(cnm_path)\n",
    "# print(\"Saved under \"+str(cnm_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T08:01:19.892729Z",
     "start_time": "2020-05-26T08:01:19.861124Z"
    }
   },
   "outputs": [],
   "source": [
    "# LOAD / GENERATE AND SAVE CORRELATION IMAGE\n",
    "if not 'Cn' in locals():\n",
    "    if glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], 'Cn.tiff')):\n",
    "        print('Loading green correlation image...')\n",
    "        if glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], 'Cn.tif*')):\n",
    "            Cn = tifffile.imread(glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], 'Cn.tif*'))[0])\n",
    "        else:\n",
    "            Cn = tifffile.imread(glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], 'Cn_green.tif*'))[0])\n",
    "    else:\n",
    "        print(\"Calculating correlation image...\")\n",
    "        Cn = cm.local_correlations(images.transpose(1, 2, 0))\n",
    "        Cn[np.isnan(Cn)] = 0\n",
    "        tifffile.imsave(os.path.join(params['paths']['Results_Imaging_Dir'], 'Cn_green.tiff'), Cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T08:02:05.972570Z",
     "start_time": "2020-05-26T08:01:43.229773Z"
    }
   },
   "outputs": [],
   "source": [
    "coords = cmviz.get_contours(cnm.estimates.A, cnm.dims)\n",
    "thresholdsource = ColumnDataSource({'span':[-1,1], 'span_log':[0.01,100], 'thr_snr': [cnm.params.quality['min_SNR']]*2, 'min_snr': [cnm.params.quality['SNR_lowest']]*2, 'thr_r': [cnm.params.quality['rval_thr']]*2, 'thr_cnn': [cnm.params.quality['min_cnn_thr']]*2, 'min_r': [cnm.params.quality['rval_lowest']]*2, 'min_cnn': [cnm.params.quality['cnn_lowest']]*2})\n",
    "\n",
    "cnm.estimates.restore_discarded_components()  \n",
    "\n",
    "def normalise_evals(val, by=1, type=float):\n",
    "    val = val.replace([np.inf, -np.inf, np.nan], 0)\n",
    "    val_bottomed = val - min(val)\n",
    "    norm = val_bottomed / max(val_bottomed) * by\n",
    "    return norm.astype(type)\n",
    "\n",
    "# Loading components' temporal traces\n",
    "Fcols = ['F_'+str(num) for num in range(len(cnm.estimates.F_dff))]\n",
    "F = pd.DataFrame(cnm.estimates.F_dff.T, index=np.array(range(len(cnm.estimates.F_dff.T))),\n",
    "          columns=Fcols)\n",
    "F['Frame'] = F.index\n",
    "Ccols = ['C_'+str(num) for num in range(len(cnm.estimates.F_dff_dec))]\n",
    "C = pd.DataFrame(cnm.estimates.F_dff_dec.T, index=np.array(range(len(cnm.estimates.F_dff_dec.T))),\n",
    "          columns=Ccols)\n",
    "Scols = ['S_'+str(num) for num in range(len(cnm.estimates.S_dff))]\n",
    "S = pd.DataFrame(cnm.estimates.S_dff.T, index=np.array(range(len(cnm.estimates.S_dff.T))),\n",
    "          columns=Scols)\n",
    "\n",
    "# Creating a 'comps' ColumnDataSource for Bokeh\n",
    "comps = pd.DataFrame()\n",
    "comps['snr'] = cnm.estimates.SNR_comp\n",
    "comps['r'] = np.array(cnm.estimates.r_values)\n",
    "comps['cnn'] = np.array(cnm.estimates.cnn_preds)\n",
    "rgbArray = np.array([normalise_evals(np.cbrt(comps['snr']), 255, 'int'), normalise_evals(comps['r'], 255, 'int'), normalise_evals(comps['cnn'], 255, 'int')]).T.tolist()\n",
    "comps['hex'] = ['#%02x%02x%02x' % tuple(i) for i in rgbArray]\n",
    "comps['good'] = 1\n",
    "comps['alpha'] = 0.5\n",
    "comps['xcoords'] = np.array([coords[x]['coordinates'][:,0] for x in range(len(coords))])\n",
    "comps['ycoords'] = np.array([coords[y]['coordinates'][:,1] for y in range(len(coords))])\n",
    "s1 = ColumnDataSource(comps)\n",
    "\n",
    "TOOLTIPS = [\n",
    "        (\"index\", \"$index\"),\n",
    "        (\"SNR\", \"@snr\"),\n",
    "        (\"R\", \"@r\"),\n",
    "        (\"CNN\", \"@cnn\"),\n",
    "        (\"good\", \"@good\")\n",
    "    ]\n",
    "\n",
    "p1 = figure(title=\"Components: \"+str(sum(s1.data['good']))+\" out of \"+str(len(s1.data['good']))+\" selected to meet criteria\", plot_height=int(scaling*640), plot_width=int(scaling*640), \n",
    "           x_range=(0,cnm.dims[0]), y_range=(cnm.dims[1], 0), tools='hover, reset, tap, pan, box_zoom, wheel_zoom',\n",
    "           active_scroll = \"wheel_zoom\", tooltips=TOOLTIPS)\n",
    "\n",
    "def update(thr_snr=cnm.params.quality['min_SNR'], thr_r=cnm.params.quality['rval_thr'], thr_cnn=cnm.params.quality['min_cnn_thr'], min_snr=cnm.params.quality['SNR_lowest'], min_r=cnm.params.quality['rval_lowest'], min_cnn=cnm.params.quality['cnn_lowest']):\n",
    "    s1.data['good'] = (((comps['snr']>thr_snr).astype(int) + (comps['r']>thr_r).astype(int) + (comps['cnn']>thr_cnn).astype(int) >= 2) & ((comps['snr']>min_snr) & (comps['r']>min_r) & (comps['cnn']>min_cnn)).astype(int))\n",
    "    thresholdsource.data['thr_snr'] = [thr_snr]*2\n",
    "    thresholdsource.data['min_snr'] = [min_snr]*2\n",
    "    thresholdsource.data['thr_r'] = [thr_r]*2\n",
    "    thresholdsource.data['min_r'] = [min_r]*2\n",
    "    thresholdsource.data['thr_cnn'] = [thr_cnn]*2\n",
    "    thresholdsource.data['min_cnn'] = [min_cnn]*2\n",
    "    p1.title.text = \"Components: \"+str(sum(s1.data['good']))+\" out of \"+str(len(s1.data['good']))+\" selected\"\n",
    "    push_notebook()\n",
    "\n",
    "im = p1.image(image=[np.flip(Cn, axis=0)], x=[0], y=[Cn.shape[1]],\n",
    "           dw=[Cn.shape[0]], dh=[Cn.shape[1]], palette='Greys256')#'Viridis256')\n",
    "r = p1.patches('xcoords', \n",
    "               'ycoords', \n",
    "               line_color='white', \n",
    "               selection_line_color='white',\n",
    "               nonselection_line_color='white',\n",
    "               line_alpha='alpha',\n",
    "               selection_line_alpha=1,\n",
    "               nonselection_line_alpha=.5,\n",
    "               fill_color='hex',\n",
    "               selection_fill_color='hex',\n",
    "               fill_alpha='good', \n",
    "               selection_fill_alpha=1,\n",
    "               source=s1)\n",
    "r.nonselection_glyph.line_dash = r.data_source.data['good']\n",
    "\n",
    "s2 = ColumnDataSource(data=dict(x=[], y=[]))\n",
    "s3 = ColumnDataSource(data=F)\n",
    "s4 = ColumnDataSource(data=dict(x=[], y=[]))\n",
    "s5 = ColumnDataSource(data=C)\n",
    "s6 = ColumnDataSource(data=dict(x=[], y=[]))\n",
    "s7 = ColumnDataSource(data=S)\n",
    "\n",
    "TOOLTIPS_TRACES = [\n",
    "        (\"Y\", \"@y\"),\n",
    "        (\"X\", \"@x\"),\n",
    "    ]\n",
    "\n",
    "p2 = figure(title=\"Traces\", x_axis_label='Frames', y_axis_label=u'\\u0394F/F', plot_height=int(scaling*250), plot_width=int(scaling*900), x_range=(0,F.shape[0]), y_range=(-1, 1), tools='reset, pan, box_zoom', toolbar_location='above')\n",
    "p2.extra_y_ranges = {\"deconv\": Range1d(start=-.1, end=2)}\n",
    "p2.add_layout(LinearAxis(y_range_name=\"deconv\", axis_label='AU'), 'right')\n",
    "p2.line('x', 'y', source=s2, line_color='blue', alpha=.5, legend_label=u'\\u0394F/F', line_width=scaling*1)\n",
    "p2.line('x', 'y', source=s4, line_color='green', alpha=.5, y_range_name=\"deconv\", legend_label='Deconvolved', line_width=scaling*1)\n",
    "p2.line('x', 'y', source=s6, line_color='red', alpha=.5, y_range_name=\"deconv\", legend_label='Events', line_width=scaling*1)\n",
    "p2.add_tools(HoverTool(mode='vline', tooltips=TOOLTIPS_TRACES))\n",
    "p2.legend.glyph_width = 10\n",
    "p2.legend.label_width = 20\n",
    "p2.legend.orientation = \"horizontal\"\n",
    "\n",
    "p3 = figure(title=\"Quality: SNR v r\", plot_height=int(scaling*220), plot_width=int(scaling*220),\n",
    "           x_axis_label='SNR', x_axis_type='log', y_axis_label='r', tools='tap, hover', x_range=(min(comps['snr']), max(comps['snr'][np.isfinite(comps['snr'])])), y_range=(min(comps['r']), max(comps['r'])), tooltips=TOOLTIPS)\n",
    "scatter1 = p3.circle('snr', 'r', fill_color='hex', size=scaling*6, \n",
    "                    alpha=.7, line_color='black', line_width=scaling*.8, line_alpha='good', \n",
    "                    nonselection_fill_color='black', source=s1)\n",
    "p3.line(x='thr_snr', y='span', line_width=scaling*2, line_color='red', line_dash='dotted', source=thresholdsource)\n",
    "p3.line(x='min_snr', y='span', line_width=scaling*2, line_color='red', source=thresholdsource)\n",
    "p3.line(x='span_log', y='thr_r', line_width=scaling*2, line_color='green', line_dash='dotted', source=thresholdsource)\n",
    "p3.line(x='span_log', y='min_r', line_width=scaling*2, line_color='green', source=thresholdsource)\n",
    "\n",
    "p4 = figure(title=\"Quality: SNR v CNN\", plot_height=int(scaling*220), plot_width=int(scaling*220),\n",
    "           x_axis_label='SNR', y_axis_label='CNN', tools='tap, hover', x_axis_type='log', x_range=(min(comps['snr']), max(comps['snr'][np.isfinite(comps['snr'])])), y_range=(min(comps['cnn']), max(comps['cnn'])), tooltips=TOOLTIPS)\n",
    "scatter2 = p4.circle('snr', 'cnn', fill_color='hex', size=scaling*6, \n",
    "                    alpha=.7, line_color='black', line_width=scaling*.8, line_alpha='good', \n",
    "                    nonselection_fill_color='black', source=s1)\n",
    "p4.line(x='thr_snr', y='span', line_width=scaling*2, line_color='red', line_dash='dotted', source=thresholdsource)\n",
    "p4.line(x='min_snr', y='span', line_width=scaling*2, line_color='red', source=thresholdsource)\n",
    "p4.line(x='span_log', y='thr_cnn', line_width=scaling*2, line_color='blue', line_dash='dotted', source=thresholdsource)\n",
    "p4.line(x='span_log', y='min_cnn', line_width=scaling*2, line_color='blue', source=thresholdsource)\n",
    "\n",
    "p5 = figure(title=\"Quality: CNN v r\", plot_height=int(scaling*220), plot_width=int(scaling*220),\n",
    "           x_axis_label='CNN', y_axis_label='r', tools='tap, hover', x_range=(min(comps['cnn']), max(comps['cnn'])), y_range=(min(comps['r']), max(comps['r'])), tooltips=TOOLTIPS)\n",
    "scatter3 = p5.circle('cnn', 'r', fill_color='hex', size=scaling*6, \n",
    "                    alpha=.7, line_color='black', line_width=scaling*.8, line_alpha='good', \n",
    "                    nonselection_fill_color='black', source=s1)\n",
    "p5.line(x='thr_cnn', y='span', line_width=scaling*2, line_color='blue', line_dash='dotted', source=thresholdsource)\n",
    "p5.line(x='min_cnn', y='span', line_width=scaling*2, line_color='blue', source=thresholdsource)\n",
    "p5.line(x='span', y='thr_r', line_width=scaling*2, line_color='green', line_dash='dotted', source=thresholdsource)\n",
    "p5.line(x='span', y='min_r', line_width=scaling*2, line_color='green', source=thresholdsource)\n",
    "\n",
    "s1.selected.js_on_change('indices', CustomJS(args={\n",
    "    'title': p2.title, 's1':s1, 's2':s2, 's3':s3, 's4':s4, 's5':s5, 's6':s6, 's7':s7\n",
    "    }, code=\"\"\"\n",
    "        var inds = cb_obj.indices;\n",
    "        var d1 = s1.data;\n",
    "        var d2 = s2.data;\n",
    "        var d3 = s3.data;\n",
    "        var d4 = s4.data;\n",
    "        var d5 = s5.data;\n",
    "        var d6 = s6.data;\n",
    "        var d7 = s7.data;\n",
    "        var F_idx = 'F_' + inds[0]\n",
    "        var C_idx = 'C_' + inds[0]\n",
    "        var S_idx = 'S_' + inds[0]\n",
    "        d2['x'] = d3['Frame']\n",
    "        d2['y'] = d3[F_idx]\n",
    "        d4['x'] = d3['Frame']\n",
    "        d4['y'] = d5[C_idx]\n",
    "        d6['x'] = d3['Frame']\n",
    "        d6['y'] = d7[S_idx]\n",
    "        var snr = Math.round(d1['snr'][inds[0]] * 100) / 100\n",
    "        var r = Math.round(d1['r'][inds[0]] * 100) / 100\n",
    "        var cnn = Math.round(d1['cnn'][inds[0]] * 100) / 100\n",
    "        var goodness = d1['good'][inds[0]]\n",
    "        title.text = 'Component: ' + inds[0] + ', SNR: ' + snr + ', R: ' + r + ', CNN: ' + cnn + ', good: ' + goodness\n",
    "        s2.change.emit();\n",
    "        s4.change.emit();\n",
    "        s6.change.emit();\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "quality_col = column(p3,p4,p5)\n",
    "row1 = row(p2)\n",
    "row2 = row(p1, quality_col)\n",
    "layout = column(row1, row2)\n",
    "print(\"{} components found in file.\".format(len(comps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PERFORMANCE CAN BE PROBLEMATIC WITH >800 COMPONENTS! IF BROWSER CRASHES, OMMIT THIS CELL\n",
    "\n",
    "show(layout, notebook_handle=True)\n",
    "interact(update, \n",
    "         thr_snr=(0,np.percentile(comps['snr'], 95),.1), \n",
    "         thr_r=(-0.5,1,.01), \n",
    "         thr_cnn=(0,1,.01),\n",
    "         min_snr=(0,np.percentile(comps['snr'], 95),.1), \n",
    "         min_r=(-0.5,1,.01), \n",
    "         min_cnn=(0,1,.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T08:02:34.212058Z",
     "start_time": "2020-05-26T08:02:34.196791Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE AND FILTER COMPONENTS BASED ON NEW THRESHOLDS\n",
    "\n",
    "new_quality = {}\n",
    "new_quality['min_SNR'] = thresholdsource.data['thr_snr'][0]\n",
    "new_quality['rval_thr'] = thresholdsource.data['thr_r'][0]\n",
    "new_quality['min_cnn_thr'] = thresholdsource.data['thr_cnn'][0]\n",
    "new_quality['SNR_lowest'] = 1.3#thresholdsource.data['min_snr'][0]\n",
    "new_quality['rval_lowest'] = thresholdsource.data['min_r'][0]\n",
    "new_quality['cnn_lowest'] = thresholdsource.data['min_cnn'][0]\n",
    "cnm.estimates.filter_components(images, cnm.params, new_quality)\n",
    "# cnm.save(cnm2_path)\n",
    "print(\"Saved under \"+str(cnm2_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T08:02:57.587486Z",
     "start_time": "2020-05-26T08:02:57.228029Z"
    }
   },
   "outputs": [],
   "source": [
    "scaling = 1.5\n",
    "if not cnm.estimates.idx_components.any():\n",
    "    cnm.estimates.restore_discarded_components()\n",
    "quality_rank = scipy.stats.rankdata(cnm.estimates.SNR_comp)# + scipy.stats.rankdata(cnm.estimates.r_values) + scipy.stats.rankdata(cnm.estimates.cnn_preds)\n",
    "idx = [value for value in np.argsort(quality_rank) if value in cnm.estimates.idx_components]  # all filtered components sorted by their quality, starting with the lowest\n",
    "i = 0\n",
    "idx_curated = []\n",
    "idx_curated_bad = []\n",
    "\n",
    "traces = pd.DataFrame()\n",
    "traces['x'] = np.array(range(len(cnm.estimates.F_dff.T)))\n",
    "traces['C'] = cnm.estimates.F_dff_dec[idx[0]]\n",
    "traces['S'] = cnm.estimates.S_dff[idx[0]]\n",
    "traces['F'] = cnm.estimates.F_dff[idx[0]]\n",
    "tracesource = ColumnDataSource(data=traces)\n",
    "\n",
    "trace_hover = HoverTool(mode='vline', names=[\"line_with_hovertool\"])\n",
    "trace_hover.tooltips = \"\"\"\n",
    "    <style>\n",
    "        .bk-tooltip>div:not(:first-child) {display:none;}\n",
    "    </style>\n",
    "\n",
    "    <b>Frame: </b> @x <br>\n",
    "    <b>dF/F: </b> @F <br>\n",
    "    <b>C: </b> @C <br>\n",
    "    <b>S: </b> @S\n",
    "\"\"\"\n",
    "\n",
    "p20 = figure(x_axis_label='Frames', y_axis_label=u'\\u0394F/F', plot_height=int(scaling*250), plot_width=int(scaling*900), x_range=(0,F.shape[0]), y_range=(min(tracesource.data['F'])-max(tracesource.data['F']), max(tracesource.data['F'])), tools=[trace_hover, 'reset, crosshair, pan, box_zoom'], toolbar_location='above')\n",
    "p20.extra_y_ranges = {\"deconv\": Range1d(start=-.1, end=2)}\n",
    "p20.add_layout(LinearAxis(y_range_name=\"deconv\", axis_label='AU'), 'right')\n",
    "p20.title.text = 'Component: ' + str(idx[i]) + '/' + str(max(idx)) + ', SNR: ' + str(round(comps['snr'][idx[i]]*100)/100) + ', r: ' + str(round(comps['r'][idx[i]]*100)/100) + ', CNN: ' + str(round(comps['cnn'][idx[i]]*100)/100)\n",
    "f = p20.line('x', 'F', line_color='blue', alpha=.5, line_width=scaling*1, source = tracesource, name=\"line_with_hovertool\")\n",
    "c = p20.line('x', 'C', line_color='green', alpha=.5, y_range_name=\"deconv\", line_width=scaling*1, source=tracesource)\n",
    "s = p20.line('x', 'S', line_color='red', alpha=.5, y_range_name=\"deconv\", line_width=scaling*1, source=tracesource)\n",
    "legend = Legend(location=\"center\",\n",
    "                   glyph_width=10,\n",
    "                   label_width=20,\n",
    "                    items=[\n",
    "                    (u'\\u0394F/F', [f]),\n",
    "                    (\"Deconvolved\", [c]),\n",
    "                    (\"Events\", [s]),\n",
    "    ])\n",
    "p20.add_layout(legend, 'right')\n",
    "\n",
    "p10 = figure(plot_height=int(scaling*640), plot_width=int(scaling*640), \n",
    "       x_range=(0,cnm.dims[0]), y_range=(cnm.dims[1], 0), tools='reset, tap, pan, box_zoom, wheel_zoom',\n",
    "       active_scroll = \"wheel_zoom\")\n",
    "p10.image(image=[np.flip(Cn, axis=0)], x=[0], y=[Cn.shape[1]], dw=[Cn.shape[0]], dh=[Cn.shape[1]], palette='Viridis256')\n",
    "q = p10.patches(comps['xcoords'][idx], comps['ycoords'][idx], line_color='white', line_alpha=1, line_width=scaling*1, line_dash='dotted', fill_alpha=0)\n",
    "r = p10.patch(comps['xcoords'][idx[i]], comps['ycoords'][idx[i]], line_color='red', line_alpha=1, line_width=scaling*3, fill_alpha=0)\n",
    "\n",
    "buttonYes = widgets.Button(description='Accept')\n",
    "buttonYes.style.button_color = 'lightgreen'\n",
    "buttonNo = widgets.Button(description='Reject', button_style='danger')\n",
    "buttonNo.style.button_color = 'red'\n",
    "display(buttonYes); display(buttonNo)\n",
    "layout = column(p20, p10)\n",
    "show(layout, notebook_handle=True)\n",
    "      \n",
    "def on_button_clicked_yes(b):\n",
    "    global i\n",
    "    if i < len(idx)-1:\n",
    "        idx_curated.append(idx[i])\n",
    "        i+=1\n",
    "        p20.title.text = 'Component: ' + str(idx[i]) + '/' + str(max(idx)) + ', SNR: ' + str(round(comps['snr'][idx[i]]*100)/100) + ', r: ' + str(round(comps['r'][idx[i]]*100)/100) + ', CNN: ' + str(round(comps['cnn'][idx[i]]*100)/100)\n",
    "        tracesource.data['C'] = cnm.estimates.F_dff_dec[idx[i]]\n",
    "        tracesource.data['S'] = cnm.estimates.S_dff[idx[i]]\n",
    "        tracesource.data['F'] = cnm.estimates.F_dff[idx[i]]\n",
    "        p20.y_range.start = min(tracesource.data['F'])-max(tracesource.data['F'])\n",
    "        p20.y_range.end   = max(tracesource.data['F'])\n",
    "        p20.extra_y_ranges['deconv'].start = min(tracesource.data['C'])-.01*max(tracesource.data['C'])\n",
    "        p20.extra_y_ranges['deconv'].end = 2*max(tracesource.data['C'])\n",
    "        r = p10.patch(comps['xcoords'][idx[i]], comps['ycoords'][idx[i]], line_color='red', line_alpha=1, line_width=scaling*3, fill_alpha=0)\n",
    "        if idx_curated:\n",
    "            r = p10.patch(comps['xcoords'][idx_curated[-1]], comps['ycoords'][idx_curated[-1]], line_alpha=1, line_color='white', line_width=scaling*3, fill_alpha=1, fill_color='white')\n",
    "        if idx_curated_bad:\n",
    "            r = p10.patch(comps['xcoords'][idx_curated_bad[-1]], comps['ycoords'][idx_curated_bad[-1]], line_alpha=1, line_color='black', line_width=scaling*3, fill_alpha=1, fill_color='black')\n",
    "        push_notebook()\n",
    "    else:\n",
    "        print(\"All components curated.\")\n",
    "\n",
    "def on_button_clicked_no(b):\n",
    "    global i\n",
    "    if i < len(idx)-1:\n",
    "        idx_curated_bad.append(idx[i])\n",
    "        i+=1\n",
    "        p20.title.text = 'Component: ' + str(idx[i]) + '/' + str(max(idx)) + ', SNR: ' + str(round(comps['snr'][idx[i]]*100)/100) + ', r: ' + str(round(comps['r'][idx[i]]*100)/100) + ', CNN: ' + str(round(comps['cnn'][idx[i]]*100)/100)\n",
    "        tracesource.data['C'] = cnm.estimates.F_dff_dec[idx[i]]\n",
    "        tracesource.data['S'] = cnm.estimates.S_dff[idx[i]]\n",
    "        tracesource.data['F'] = cnm.estimates.F_dff[idx[i]]\n",
    "        p20.y_range.start = min(tracesource.data['F'])-max(tracesource.data['F'])\n",
    "        p20.y_range.end   = max(tracesource.data['F'])\n",
    "        p20.extra_y_ranges['deconv'].start = min(tracesource.data['C'])-.01*max(tracesource.data['C'])\n",
    "        p20.extra_y_ranges['deconv'].end = 2*max(tracesource.data['C'])\n",
    "        r = p10.patch(comps['xcoords'][idx[i]], comps['ycoords'][idx[i]], line_color='red', line_alpha=1, line_width=scaling*3, fill_alpha=0)\n",
    "        if idx_curated:\n",
    "            r = p10.patch(comps['xcoords'][idx_curated[-1]], comps['ycoords'][idx_curated[-1]], line_alpha=1, line_color='white', line_width=scaling*3, fill_alpha=1, fill_color='white')\n",
    "        if idx_curated_bad:\n",
    "            r = p10.patch(comps['xcoords'][idx_curated_bad[-1]], comps['ycoords'][idx_curated_bad[-1]], line_alpha=1, line_color='black', line_width=scaling*3, fill_alpha=1, fill_color='black')\n",
    "        push_notebook()\n",
    "    else:\n",
    "        print(\"All components curated.\")\n",
    "        \n",
    "buttonYes.on_click(on_button_clicked_yes)\n",
    "buttonNo.on_click(on_button_clicked_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T08:58:59.601945Z",
     "start_time": "2020-05-26T08:58:56.019416Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE CURATED SELECTION\n",
    "include_uncurated = True  # if set to TRUE, 'good' index will include all filtered components that have not been curated (yet)\n",
    "if include_uncurated: \n",
    "    idx_curated = [item for item in idx if item not in idx_curated_bad]\n",
    "print(str(len(idx_curated))+\" components selected:\")\n",
    "print(idx_curated)\n",
    "print('Saving new component selection as '+cnm3_path+'...')\n",
    "cnm.estimates.select_components(idx_components=idx_curated, save_discarded_components=True)\n",
    "cnm.save(cnm3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T08:59:52.288485Z",
     "start_time": "2020-05-26T08:59:50.563381Z"
    }
   },
   "outputs": [],
   "source": [
    "shift = 0\n",
    "# PREPARE RED CHANNEL DATA\n",
    "#if not glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], '*RedAvg.tif*')):\n",
    "#    if glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], '*red*order_F*mmap')):\n",
    "#        print(\"Saving red average image...\")\n",
    "#        images_red = cm.load(glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], '*red*order_F*mmap'))[0])\n",
    "#        redAvg = np.mean(images_red[:1000, :, :], axis=0)\n",
    "#        tifffile.imsave(os.path.join(params['paths']['Results_Imaging_Dir'], 'RedAvg.tiff'), redAvg)\n",
    "#    else:\n",
    "#        sys.exit(\"No red channel average image found.\")\n",
    "\n",
    "# if not 'redAvg' in locals():\n",
    "redAvg = tifffile.imread(glob.glob(os.path.join(params['paths']['Results_Imaging_Dir'], '*RedAvg.tif*'))[0])\n",
    "coords = cmviz.get_contours(cnm.estimates.A, cnm.dims)\n",
    "comps = pd.DataFrame()\n",
    "comps.index.name = 'Component'\n",
    "comps['xcoords'] = np.array([coords[x]['coordinates'][:,0] for x in range(len(coords))])\n",
    "comps['ycoords'] = np.array([coords[y]['coordinates'][:,1] for y in range(len(coords))])\n",
    "comps['redness'] = np.nan\n",
    "for i in range(len(cnm.estimates.C)):\n",
    "    mask = cnm.estimates.A[:, i].toarray().reshape(cnm.dims[0], cnm.dims[1]).T\n",
    "    comps['redness'][i] = np.mean(mask * redAvg) / np.mean(mask)\n",
    "thr_red = np.percentile(redAvg.flatten(), 90)\n",
    "comps['red'] = comps['redness'] > thr_red\n",
    "inds = [i for i, x in enumerate(comps['red']) if x]\n",
    "alpha = .7\n",
    "comps['alpha'] = [alpha] * len(comps['red'])\n",
    "comps['red_alpha'] = comps['red'] * alpha\n",
    "s1 = ColumnDataSource(comps)\n",
    "if shift:\n",
    "    if shift > 0:\n",
    "        redAvg[:shift, :] = np.nan\n",
    "    elif shift < 0:\n",
    "        redAvg[shift:, :] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T09:00:00.738655Z",
     "start_time": "2020-05-26T09:00:00.179226Z"
    }
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.resources import INLINE\n",
    "bokeh.io.output_notebook(INLINE)\n",
    "scaling=2\n",
    "\n",
    "TOOLTIPS = [\n",
    "        (\"index\", \"$index\"),\n",
    "        (\"redness\", \"@redness\")\n",
    "    ]\n",
    "\n",
    "p100 = figure(plot_height=int(scaling*640), plot_width=int(scaling*640), \n",
    "   x_range=(0,cnm.dims[0]), y_range=(cnm.dims[1], 0), tools='reset, tap, pan, box_select, lasso_select, box_zoom, wheel_zoom',\n",
    "   title='Threshold: {0:.3f}'.format(thr_red)+', {} red components: {}'.format(len(inds), str(inds)), tooltips=TOOLTIPS)\n",
    "p100.image(image=[np.flip(redAvg, axis=0)], x=[0], y=[redAvg.shape[1]], dw=[redAvg.shape[0]], dh=[redAvg.shape[1]], palette='Turbo256')\n",
    "r100 = p100.patches('xcoords', \n",
    "                    'ycoords', \n",
    "                    fill_color=None, \n",
    "                    selection_fill_color=None,\n",
    "                    nonselection_fill_color=None,\n",
    "                    line_color='white', \n",
    "                    selection_line_color='red',\n",
    "                    nonselection_line_color='white',\n",
    "                    line_width=2, \n",
    "                    source=s1, \n",
    "                    line_alpha='alpha',\n",
    "                    selection_line_alpha='alpha',\n",
    "                    nonselection_line_alpha='alpha'\n",
    "                    )\n",
    "r101 = p100.patches('xcoords', 'ycoords', fill_color=None, line_color='red', line_width=2, line_alpha='red_alpha', source=s1)\n",
    "\n",
    "def update_alpha(alpha=.7):\n",
    "    s1.data['alpha'] = [alpha] * len(s1.data['red'])\n",
    "    s1.data['red_alpha'] = s1.data['red']*alpha\n",
    "    push_notebook()\n",
    "    \n",
    "def update_redthr(thr_red):\n",
    "    s1.data['red'] = s1.data['redness'] > thr_red\n",
    "    s1.data['red_alpha'] = s1.data['red']*alpha\n",
    "    inds = [i for i, x in enumerate(s1.data['red']) if x]\n",
    "    p100.title.text = 'Threshold: {0:.3f}'.format(thr_red)+', red components: '+str(inds)\n",
    "    push_notebook()\n",
    "    \n",
    "slider = widgets.FloatSlider(value=.7, min=0, max=1, step=.01, layout=Layout(width='30%', height='80px'))\n",
    "slider_thr = widgets.FloatSlider(value=thr_red, min=0, max=np.nanpercentile(redAvg.flatten(), 99.8), step=.01, layout=Layout(width='30%', height='80px'))\n",
    "\n",
    "s1.selected.js_on_change('indices', CustomJS(args={\n",
    "    's1': s1\n",
    "    }, code=\"\"\"\n",
    "        var inds = cb_obj.indices;\n",
    "        s1.data['red'][inds] = 1;\n",
    "        s1.change.emit();\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        IPython.notebook.kernel.execute(\"inds = \" + inds);\n",
    "        IPython.notebook.kernel.execute(\"updateInds(inds)\");\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "show(p100, notebook_handle=True)\n",
    "interact(update_alpha, alpha=slider)\n",
    "interact(update_redthr, thr_red=slider_thr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_threshold = True\n",
    "if use_threshold:\n",
    "    inds = [i for i, x in enumerate(s1.data['red']) if x]\n",
    "print('Marking {} components: {} as red.'.format(len(inds), inds))\n",
    "comps['red'] = False\n",
    "comps['red'].loc[inds] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'paths': {'Results_Dir': '/Users/Oliver/Google Drive/Imaging_Results'}}\n",
    "print('Loading components.hdf and merging data...')\n",
    "components = pd.read_hdf(os.path.join(params['paths']['Results_Dir'], 'components.hdf'))\n",
    "components = components.drop_duplicates()\n",
    "\n",
    "if not 'Red' in components:\n",
    "    components['Red'] = np.nan\n",
    "    \n",
    "# if not index in components.index.get_level_values('ExpIndex'):\n",
    "components_new = pd.DataFrame(index=pd.MultiIndex.from_product([[int(index)], np.arange(len(cnm.estimates.C)).tolist()], names=['ExpIndex', 'Component']),dtype=np.float64)\n",
    "components_new['Red'] = comps['red'].tolist()\n",
    "components = pd.concat([components, components_new], sort=True)\n",
    "# else:\n",
    "#     components.loc[index]['Red'] = comps['red']\n",
    "\n",
    "components.to_hdf(os.path.join(params['paths']['Results_Dir'], 'components.hdf'), key='components')\n",
    "print(\"Saved to \"+str(os.path.join(params['paths']['Results_Dir'], 'components.hdf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY ENTIRE COMPONENTS DATAFRAME\n",
    "# components = pd.read_hdf(os.path.join(params['paths']['Results_Dir'], 'components.hdf'))\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps.index.name = 'Component'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components.loc[index]['Red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caiman]",
   "language": "python",
   "name": "conda-env-caiman-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

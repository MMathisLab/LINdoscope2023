{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obarnstedt/LINdoscope2023/blob/main/notebooks/analysis_1p/lindoscope_1P_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b876a095",
      "metadata": {
        "id": "b876a095"
      },
      "source": [
        "**Can we decode behaviors from cell responses?**\n",
        "\n",
        "This notebook details how we can use a logistic regression to estimate the probability of a behavior occuring, given the cell response. We use manually annotated behaviors of an animal performing the helping behavior task to understand what is happening in the dorsal hippocampus(dHC). We use a 1P miniscope to image the dHC and caiman to obtain the deconnvolved activity/spikes for the active cells in the dHC.  \n",
        "\n",
        "Logistic regressor:\n",
        "Models the probability of a behavior event taking place based on the independent variables, here the spike inferred activity obtained from Caiman analysis."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ys1c7t2cW1aR"
      },
      "id": "Ys1c7t2cW1aR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "003cdfe9",
      "metadata": {
        "id": "003cdfe9"
      },
      "source": [
        "1. The first step is to create a design matrix that contains all the behavior variables you are interested in. Our design matrix here contains the manually annotated data. When the animal is performing the behavior, the design matrix is filled with 1's and when the animal is not performing the behavior it is filled with 0's.\n",
        "\n",
        "2. Once we have the design matrix, we can choose which behaviors we want to decode. We use a logistic regression to look for the relationship between the stimulus(i.e the behavior) and the response(i.e S mat)\n",
        "\n",
        "3. We will then shuffle the S mat activity and compute the shuffled decoder performance. Using the shuffled performance and decoder performance, we can calculate the percentile score from which we can see how many cells respond to the behavior of interest."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/obarnstedt/LINdoscope2023.git"
      ],
      "metadata": {
        "id": "pxgiZ2G1EcbI",
        "outputId": "ff7f5b6c-d7a4-47fc-c692-b606d2b1773f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pxgiZ2G1EcbI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LINdoscope2023'...\n",
            "remote: Enumerating objects: 399, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 399 (delta 20), reused 29 (delta 4), pack-reused 336\u001b[K\n",
            "Receiving objects: 100% (399/399), 83.89 MiB | 14.93 MiB/s, done.\n",
            "Resolving deltas: 100% (214/214), done.\n",
            "Updating files: 100% (50/50), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a949d020",
      "metadata": {
        "id": "a949d020"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from LINdoscope2023.notebooks.analysis_1p.utils.designmatrix_utils import *\n",
        "from LINdoscope2023.notebooks.analysis_1p.utils.logistic_regression_utils import *\n",
        "from LINdoscope2023.notebooks.analysis_1p.utils.plotting_utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6498ae97",
      "metadata": {
        "id": "6498ae97"
      },
      "outputs": [],
      "source": [
        "drive_path = '/content/drive' #Change this to point to where you have your sample data\n",
        "data_path = os.path.join(os.getcwd(), 'data')\n",
        "\n",
        "if not os.listdir(data_path):\n",
        "    print(f'{data_path} is empty. Check if data has been downloaded and placed in the correct folder. Or check that file name and types')\n",
        "\n",
        "manual_annotation_file = glob.glob(os.path.join(data_path, '*_manual_annotations.csv*'))[0]\n",
        "path, name = os.path.split(manual_annotation_file)\n",
        "s_mat_file = glob.glob(os.path.join(data_path, '*_spikes.npy*'))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e846e6c",
      "metadata": {
        "id": "2e846e6c"
      },
      "outputs": [],
      "source": [
        "#Create a folder to save the outputs of this notebook\n",
        "save_results_fold = os.path.join(data_path, 'output')\n",
        "\n",
        "if not os.path.exists(save_results_fold):\n",
        "    os.mkdir(save_results_fold)\n",
        "    print('Folder %s created!' % save_results_fold)\n",
        "else:\n",
        "    print('Folder %s already exists!' % save_results_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ed5f98",
      "metadata": {
        "id": "13ed5f98"
      },
      "outputs": [],
      "source": [
        "#Load the S_mat data and see how the raw traces look for some cells\n",
        "s_mat = np.load(s_mat_file, allow_pickle=True)\n",
        "\n",
        "cell_idx = 10 #The id of the cell you want to see the traces for\n",
        "plot_smat(s_mat, cell_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60aafe38",
      "metadata": {
        "id": "60aafe38"
      },
      "outputs": [],
      "source": [
        "#Let's create our design matrix with some sample data here:\n",
        "#Which behaviors are we interested in for the design matrix?\n",
        "behaviors = ['exploratory behaviors', 'task behaviors', 'appraisel behaviors', 'defensive behaviors',\n",
        "            'prosocial behaviors']\n",
        "\n",
        "#If we are interested in adding a pre-behavior time set add_backward_jitter=True and set how much time(frames)\n",
        "#you want to add with the backward=5 parameter. Similarly, you can add a post-behavior time using the\n",
        "#add_forward_jitter and forward parameters.\n",
        "\n",
        "design_matrix = create_design_matrix(manual_annotation_file, save_results_fold, s_mat, n_beh_events=behaviors,\n",
        "                         add_forward_jitter=True, forward=5, add_back_jitter=True, backward=5,\n",
        "                         fps=30, to_use='Regrouped Behaviors')\n",
        "\n",
        "#Plot a ethogram for the behaviors\n",
        "plot_design_matrix(design_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5531602",
      "metadata": {
        "id": "f5531602"
      },
      "source": [
        "Let's choose one behavior that we are interested in. I am choosing 'task_behaviors' here.\n",
        "Feel free to change the 'behavior_decode' parameter below to see how the decoder behaves for different behaviors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08791c3e",
      "metadata": {
        "id": "08791c3e"
      },
      "outputs": [],
      "source": [
        "behavior_decode = 'task behaviors'\n",
        "stimulus = (design_matrix[behavior_decode].values).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aacd2495",
      "metadata": {
        "id": "aacd2495"
      },
      "outputs": [],
      "source": [
        "#Bin the data (the s_mat and the design matrix)\n",
        "\n",
        "#Set some binning parameters\n",
        "bin_step = 30\n",
        "bin_start = 0\n",
        "bin_stop = stimulus.shape[0]\n",
        "\n",
        "#func parameter: the function on each bin. Change to np.mean to see how this changes the bin values\n",
        "binned_smat = bin_data(s_mat.T, bin_step, bin_start, bin_stop, func=np.max)\n",
        "plot_binned_data(s_mat.T, binned_smat, cell_idx=10)\n",
        "\n",
        "binned_stimulus = bin_data(stimulus, bin_step, bin_start, bin_stop, func=np.max)\n",
        "plot_binned_data(stimulus, binned_stimulus, cell_idx=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e58d4d3",
      "metadata": {
        "id": "5e58d4d3"
      },
      "outputs": [],
      "source": [
        "#Split the data into test and train\n",
        "X_train, X_test, Y_train, Y_test = data_splitter(binned_smat, binned_stimulus)\n",
        "\n",
        "#Check to make sure our training data has enough values of each class.\n",
        "#Class 0: behavior does not occur\n",
        "#Class 1: behavior occurs\n",
        "counter = Counter(Y_train.flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3872cb4",
      "metadata": {
        "id": "f3872cb4"
      },
      "outputs": [],
      "source": [
        "#Synthetic Minority Over-sampling(SMOTE)\n",
        "\n",
        "#The classification categories are not eqully(approximately) represented in our current dataset. We have only a small\n",
        "#percentage of 'interesting' behavior samples. We can undersample the majority class, proposed before and\n",
        "#implemented. However, undersampling the majority class, and over sampling the minority class to create a more\n",
        "#balances dataset for the decoder to train on will result in a better decoder performance.\n",
        "\n",
        "if counter[0] and counter[1] > 4:\n",
        "    X_train, Y_train = oversampler(X_train, Y_train, sampling_strategy=0.4)\n",
        "else:\n",
        "    print('Not enough values to create synthetic values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66f4282b",
      "metadata": {
        "id": "66f4282b"
      },
      "outputs": [],
      "source": [
        "print('Training and fitting model.')\n",
        "\n",
        "Y_fit_train, Y_fit, accuracy_log_reg, recall_score_log_reg, score_f1_log_reg, auc_score, corr_vals = logistic_regression_decoder(X_train, Y_train, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c99417a0",
      "metadata": {
        "id": "c99417a0"
      },
      "outputs": [],
      "source": [
        "#Lets see what the decoder trains on, and what it predicts during training:\n",
        "plot_train(X_train, Y_train, Y_fit_train, cell_idx=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819a9d61",
      "metadata": {
        "id": "819a9d61"
      },
      "outputs": [],
      "source": [
        "#Lets see what the decoder predicts after training for one cell and it's performance:\n",
        "cell_idx=90\n",
        "plot_test(X_test, Y_test, Y_fit, cell_idx)\n",
        "print('F1 score value:{0:.2f}'.format(score_f1_log_reg[cell_idx]))\n",
        "print('Accuracy score value:{0:.2f}'.format(accuracy_log_reg[cell_idx]))\n",
        "print('Recall score value:{0:.2f}'.format(recall_score_log_reg[cell_idx]))\n",
        "print('AUC score value:{0:.2f}'.format(auc_score[cell_idx]))\n",
        "print('Correlation score value:{0:.2f}'.format(corr_vals[cell_idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1dc3b7",
      "metadata": {
        "id": "3d1dc3b7"
      },
      "outputs": [],
      "source": [
        "#How does the decoder perform for this session\n",
        "#F1 score: TP / TP + 0.5(FP + FN)\n",
        "plt.figure()\n",
        "plt.plot(score_f1_log_reg)\n",
        "plt.axhline(0.4, color='r')\n",
        "plt.xlabel('Neurons')\n",
        "plt.ylabel('F1 Score')\n",
        "sns.despine()\n",
        "\n",
        "#Recall score\n",
        "plt.figure()\n",
        "plt.plot(recall_score_log_reg)\n",
        "plt.axhline(0.7, color='r')\n",
        "plt.xlabel('Neurons')\n",
        "plt.ylabel('Recall')\n",
        "sns.despine()\n",
        "\n",
        "#Accuracy score\n",
        "plt.figure()\n",
        "plt.plot(accuracy_log_reg)\n",
        "plt.axhline(0.7, color='r')\n",
        "plt.xlabel('Neurons')\n",
        "plt.ylabel('Accuracy')\n",
        "sns.despine()\n",
        "\n",
        "#AUC score\n",
        "plt.figure()\n",
        "plt.plot(auc_score)\n",
        "plt.axhline(0.7, color='r')\n",
        "plt.xlabel('Neurons')\n",
        "plt.ylabel('AUC score')\n",
        "sns.despine()\n",
        "\n",
        "#Correlation\n",
        "plt.figure()\n",
        "plt.plot(corr_vals)\n",
        "plt.axhline(0.7, color='r')\n",
        "plt.xlabel('Neurons')\n",
        "plt.ylabel('Correlation value')\n",
        "sns.despine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aae3a3f2",
      "metadata": {
        "id": "aae3a3f2"
      },
      "outputs": [],
      "source": [
        "#Lets see how the decoder behaves when we shuffle one of the inputs to the decoder\n",
        "#(The X; which in this case is the S matrix)\n",
        "#We average the performance measures for 100 shufles. If you want to change how many shuffles,\n",
        "#change the n_shuffle parameter\n",
        "\n",
        "print('Computing the shuffled decoder performance scores')\n",
        "# Two different strategies can be used to compute the shuffled F1 scores\n",
        "score_f1_log_reg_shuffled, recall_score_log_reg_shuffled, accuracy_log_reg_shuffled, auc_score_shuffled, \\\n",
        "corr_vals_shuffled = shuffle_log_reg(X_train, Y_train, X_test, Y_test, n_shuffle=100, \\\n",
        "                                     shuffle_strategy='smat_shuffle')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07986b94",
      "metadata": {
        "id": "07986b94"
      },
      "outputs": [],
      "source": [
        "#From the shuffled performance scores and the unshuffled data, let's compute a percentile score\n",
        "#which tells us how good the decoder performed on the data compared to the shuffled data.\n",
        "\n",
        "pct_f1_log_reg = compute_pct(score_f1_log_reg_shuffled, score_f1_log_reg)\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
        "ax1.hist(pct_f1_log_reg, bins=20)\n",
        "ax1.axvline(0.95, color='r')\n",
        "ax1.set_xlabel('Bins')\n",
        "ax1.set_ylabel('No. of Neurons')\n",
        "ax1.set_title('Percentile scores')\n",
        "ax2.hist(score_f1_log_reg_shuffled[0], bins=20)\n",
        "ax3.hist(score_f1_log_reg_shuffled[10], bins=20)\n",
        "ax2.set_title('F1 scores for shuffle 0')\n",
        "ax3.set_title('F1 scores for shuffle 10')\n",
        "plt.tight_layout()\n",
        "sns.despine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174f13c3",
      "metadata": {
        "id": "174f13c3"
      },
      "outputs": [],
      "source": [
        "responding_cells_idx = np.where(pct_f1_log_reg > 0.95)[0]\n",
        "\n",
        "#Plot the predictions of the decoder for a cell with a percentile score > 0.95\n",
        "cell_idx = np.random.choice(responding_cells_idx)\n",
        "\n",
        "print('F1 score value:{0:.2f}'.format(score_f1_log_reg[responding_cell]))\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
        "ax1.plot(X_test[:, cell_idx], '-b', label='Observed spikes')\n",
        "ax2.plot(Y_fit[cell_idx, :], '-r', label='Fitted events')\n",
        "ax2.plot(Y_test, label='Behavior events')\n",
        "sns.despine()\n",
        "ax1.legend()\n",
        "ax2.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "584a7b6b",
      "metadata": {
        "id": "584a7b6b"
      },
      "outputs": [],
      "source": [
        "data_dict = {'F1 score': score_f1_log_reg, 'Accuracy': accuracy_log_reg,'Recall': recall_score_log_reg,\n",
        "             'AUC score': auc_score,'Correlation value': corr_vals, 'Percentile score F1': score_f1_log_reg}\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(data_dict, orient=\"columns\")\n",
        "csv_file_path = save_results_fold + '/' + name[:-4] + '_' + str(bin_step) + '_results.csv'\n",
        "results_df.to_csv(csv_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bed4a951",
      "metadata": {
        "id": "bed4a951"
      },
      "source": [
        "How many cells are responding to the behavior of interest?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "860f571b",
      "metadata": {
        "id": "860f571b"
      },
      "outputs": [],
      "source": [
        "print('Percentage of cells responding to behavior of interest: {0:.2f} %'.format((len(responding_cells_idx)/len(s_mat))*100))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}